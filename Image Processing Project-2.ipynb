{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Convolutional neural networks (CNNs) are similar to neural networks to the extent that both are made up of neurons, which need to have their weights and biases optimized. The main difference between the two is that CNNs make the explicit assumption that the inputs are images, which allows us to incorporate certain properties into the architecture. These properties make the forward propagation step much more efficient and reduce the number of parameters needed in the network. This makes CNNs the best choice for solving problems related to image recognition, object detection, and other computer vision applications.\n",
    "In this guide, you will learn how to build CNNs using the keras library. Let's start by loading the required libraries and packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We will use the popular MNIST dataset in this guide. Each image in the dataset has dimensions of 28x28 pixels and contains a centered, grayscale digit. The model will take the image as input, and it will output one of the ten possible digits (0 through 9). There are 70,000 images in the data, of which 60,000 will be used for training the model and the remaining 10,000 for validating the model.\n",
    "The first line of code below loads the MNIST dataset and creates the training and test arrays. The second line of code checks the shape of the second image in the training set. The result is a 28x28 pixel shape, which was expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANRElEQVR4nO3df6hcdXrH8c+ndgNigsRKYshKTVfBVqFujaHgUpR111SRZKPWzR8lVcPdP1bZQMHKRlihFKJ2t/qHCdw1mtu6ui4mYlhLdzUE0yqsXoONyaYbU0l3s/llEE0WDGni0z/uib0md75znTkzZ3Kf9wuGmTnPPec8jH5yzsx35nwdEQIw9f1e0w0A6A/CDiRB2IEkCDuQBGEHkvj9fu7MNh/9Az0WEZ5oeVdHdtsLbf/K9m7b93ezLQC95U7H2W2fI2mXpK9J2ivpTUlLI+KXhXU4sgM91osj+wJJuyPivYg4LunHkhZ1sT0APdRN2OdK+s2453urZZ9he8j2qO3RLvYFoEvdfEA30anCGafpETEsaVjiNB5oUjdH9r2SLh73/IuS9nXXDoBe6Sbsb0q6zPY829MkfVPSxnraAlC3jk/jI+KE7Xsk/UzSOZKejIgdtXUGoFYdD711tDPeswM915Mv1QA4exB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEXy8ljbPP8uXLi/Xh4eFifd26dS1rd911VyctoUMc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZUbRkyZJivd3ViY8dO1ZnO+gCR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9uRWrlxZrF9//fVdbX/Dhg1drY/6dBV223skHZV0UtKJiJhfR1MA6lfHkf36iDhcw3YA9BDv2YEkug17SPq57bdsD030B7aHbI/aHu1yXwC60O1p/LURsc/2LEkv2/6viNgy/g8iYljSsCTZLv9qAkDPdHVkj4h91f0hSS9IWlBHUwDq13HYbZ9ne8apx5K+Lml7XY0BqFc3p/GzJb1g+9R2nomIf6ulK9TmjjvuKNYfeOCBYn3atGnF+urVq4v1V155pVhH/3Qc9oh4T9Kf1tgLgB5i6A1IgrADSRB2IAnCDiRB2IEk3O5SwLXujG/Q9cTs2bNb1rZu3Vpc96KLLirW2w2d3X777cX6kSNHinXULyI80XKO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBJeSngLuu+++lrU5c+Z0te1nnnmmWGcc/ezBkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuD37GeB+fPLk+O+8cYbLWvt/vs++uijxXppDF+STp48Wayj//g9O5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kwe/ZB8CMGTOK9ZGRkY63ffz48WL9ueeeK9YZR5862h7ZbT9p+5Dt7eOWXWD7ZdvvVvcze9smgG5N5jR+naSFpy27X9KmiLhM0qbqOYAB1jbsEbFF0genLV4k6dS55YikxTX3BaBmnb5nnx0R+yUpIvbbntXqD20PSRrqcD8AatLzD+giYljSsMQPYYAmdTr0dtD2HEmq7g/V1xKAXug07BslLaseL5P0Yj3tAOiVtqfxtp+VdJ2kC23vlfQ9Sask/cT23ZJ+Lak8STeK5s6dW6xffvnlHW97+fLlxXrpt/CYWtqGPSKWtih9teZeAPQQX5cFkiDsQBKEHUiCsANJEHYgCX7iOgBuvvnmrtY/ePBgy9qmTZu62jamDo7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+wDYNasllf1kiTZE87A+6l169a1rB04cKCTljAFcWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZx8AEeWJctrVd+3aVWc7fTNzZnny3xtvvLFYv+KKK4r1W2+9tWXttddeK6779NNPF+uvvvpqsT6IOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs08BN9xwQ8vaU0891cdOzjQ0NNSy9sgjjxTXnT59et3tfKrdNNiHDx8u1qfkOLvtJ20fsr193LIHbf/W9tvV7abetgmgW5M5jV8naeEEy/8pIq6qbv9ab1sA6tY27BGxRdIHfegFQA918wHdPba3Vaf5Lb/kbHvI9qjt0S72BaBLnYZ9jaQvSbpK0n5J32/1hxExHBHzI2J+h/sCUIOOwh4RByPiZER8IumHkhbU2xaAunUUdttzxj39hqTtrf4WwGBoO85u+1lJ10m60PZeSd+TdJ3tqySFpD2SvtXDHqe80dHuPs647bbbWtaeeOKJ4rqbN28u1i+99NJi/eGHHy7WFy9e3LJ24sSJ4rqPP/54sb569epi/aWXXmpZmzdvXnHdqaht2CNi6QSL1/agFwA9xNdlgSQIO5AEYQeSIOxAEoQdSMLtLlNc687s/u3sLHLuuecW6yMjI8V6aejt+PHjxXVXrVpVrF9zzTXF+sKFE/1G6v+Vppt+//33i+suWFD+rtbateVBoauvvrplbdu2bcV177333mK93fpNiogJX3SO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsU8Dzzz/fsrZkyZI+dnKm0jh7r//fW79+fcvaypUri+uerdNgS4yzA+kRdiAJwg4kQdiBJAg7kARhB5Ig7EASjLNPAVdeeWXL2pYtW4rrnn/++XW38xndjLMfOXKkWH/ssceK9Yceeqhl7eOPPy6uezZjnB1IjrADSRB2IAnCDiRB2IEkCDuQBGEHkmg7iysG34oVK1rWuh1H37FjR7G+e/fuYr00zt7u2utr1qwp1g8cOFCs47PaHtltX2x7s+2dtnfY/k61/ALbL9t+t7qf2ft2AXRqMqfxJyT9bUT8saQ/l/Rt238i6X5JmyLiMkmbqucABlTbsEfE/ojYWj0+KmmnpLmSFkk6NS/RiKTFvWoSQPc+13t225dI+rKkX0iaHRH7pbF/EGzParHOkKSh7toE0K1Jh932dEnrJa2IiCOlD17Gi4hhScPVNvghDNCQSQ292f6CxoL+o4jYUC0+aHtOVZ8j6VBvWgRQh7ZHdo8dwtdK2hkRPxhX2ihpmaRV1f2LPekQbX300Ucdr/v6668X67fcckux/uGHH3a8b/TXZE7jr5X015Lesf12tey7Ggv5T2zfLenXkm7vTYsA6tA27BHxH5JavUH/ar3tAOgVvi4LJEHYgSQIO5AEYQeSIOxAEvzEdQoo/RT0zjvvLK579OjRYv3YsWMd9YTBw5EdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgymZgimHKZiA5wg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiibdhtX2x7s+2dtnfY/k61/EHbv7X9dnW7qfftAuhU24tX2J4jaU5EbLU9Q9JbkhZL+itJv4uIf5z0zrh4BdBzrS5eMZn52fdL2l89Pmp7p6S59bYHoNc+13t225dI+rKkX1SL7rG9zfaTtme2WGfI9qjt0a46BdCVSV+DzvZ0Sa9K+oeI2GB7tqTDkkLS32vsVP+uNtvgNB7osVan8ZMKu+0vSPqppJ9FxA8mqF8i6acRcWWb7RB2oMc6vuCkbUtaK2nn+KBXH9yd8g1J27ttEkDvTObT+K9I+ndJ70j6pFr8XUlLJV2lsdP4PZK+VX2YV9oWR3agx7o6ja8LYQd6j+vGA8kRdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmh7wcmaHZb0P+OeX1gtG0SD2tug9iXRW6fq7O0PWxX6+nv2M3Zuj0bE/MYaKBjU3ga1L4neOtWv3jiNB5Ig7EASTYd9uOH9lwxqb4Pal0RvnepLb42+ZwfQP00f2QH0CWEHkmgk7LYX2v6V7d2272+ih1Zs77H9TjUNdaPz01Vz6B2yvX3csgtsv2z73ep+wjn2GuptIKbxLkwz3uhr1/T0531/z277HEm7JH1N0l5Jb0paGhG/7GsjLdjeI2l+RDT+BQzbfyHpd5L++dTUWrYflvRBRKyq/qGcGRF/NyC9PajPOY13j3prNc3436jB167O6c870cSRfYGk3RHxXkQcl/RjSYsa6GPgRcQWSR+ctniRpJHq8YjG/mfpuxa9DYSI2B8RW6vHRyWdmma80deu0FdfNBH2uZJ+M+75Xg3WfO8h6ee237I91HQzE5h9apqt6n5Ww/2cru003v102jTjA/PadTL9ebeaCPtEU9MM0vjftRHxZ5L+UtK3q9NVTM4aSV/S2ByA+yV9v8lmqmnG10taERFHmuxlvAn66svr1kTY90q6eNzzL0ra10AfE4qIfdX9IUkvaOxtxyA5eGoG3er+UMP9fCoiDkbEyYj4RNIP1eBrV00zvl7SjyJiQ7W48dduor769bo1EfY3JV1me57taZK+KWljA32cwfZ51Qcnsn2epK9r8Kai3ihpWfV4maQXG+zlMwZlGu9W04yr4deu8enPI6LvN0k3aewT+f+WtLKJHlr09UeS/rO67Wi6N0nPauy07n81dkZ0t6Q/kLRJ0rvV/QUD1Nu/aGxq720aC9achnr7isbeGm6T9HZ1u6np167QV19eN74uCyTBN+iAJAg7kARhB5Ig7EAShB1IgrADSRB2IIn/Awu8KU1THBzqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[59000],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "CNNs identify images using pixels that are often related. However, before training the algorithm, we need to prepare the data. The first step is to reshape the inputs — X_train and X_test — as done in the first two lines of code below. The reshape function performs this task, taking in three arguments. The first argument is the number of images, shown as X_train.shape[0]. The second argument is the shape of each image (28x28), while the third argument is 1 because the images are greyscale.\n",
    "The next step is normalization of the inputs to make it easier for the network to train. The third and fourth lines of code normalize the image pixel values from 0, 255 to 0,1.\n",
    "Finally, we perform the one-hot-encoding of the target variable. This is done in the fifth and sixth lines of code below. The last two lines of code print the training, test shape and number of classes in the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train=X_train.reshape((X_train.shape[0],28,28,1)).astype('float32')\n",
    "X_test=X_test.reshape((X_test.shape[0],28,28,1)).astype('float32')\n",
    "\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "\n",
    "y_train=np_utils.to_categorical(y_train)\n",
    "y_test=np_utils.to_categorical(y_test)\n",
    "\n",
    "num_classes=y_test.shape[1]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "We will create a function to train the CNN model, which is defined as cnn_model below. The first line of code below calls for the Sequential constructor because the model type we are building is sequential in nature. From the second line of code onwards, we start using the add() function to add layers to the model.\n",
    "The first layer is a Conv2D layer that will deal with the input images, represented as two-dimensional matrices. There are 32 nodes in this layer, which has a kernel size of 5, and the activation function is relu, or Rectified Linear Activation. ReLu is the most widely used activation function in deep neural networks because of its advantages in being nonlinear as well as having the ability to not activate all the neurons at the same time. In simple terms, this means that at a time, only a few neurons are activated, making the network sparse and very efficient.\n",
    "The next step is to add a pooling layer, MaxPooling2D, followed by a regularization layer called Dropout. Between the dropout and the dense layers, there is the Flatten layer, which converts the 2D matrix data to a vector. This in turn allows the output to be processed by standard, fully connected layers.\n",
    "The next step is to add the fully connected dense layer with 128 neurons and the rectifier activation function. Next, we add the output layer, which has 10 neurons for the 10 classes and a softmax activation function. This activation function generates probability-like predictions for each class.\n",
    "The final step is to compile the model, which takes three parameters: optimizer, loss, and metrics. The optimizer controls the learning rate, which will be the adam optimizer in our case. The main advantage of the adam optimizer is that we don't need to specify the learning rate as is the case with gradient descent, thereby saving us the task of optimizing the learning rate for our model. We will use the categorical_crossentropy loss function, which is the common choice for classification problems. In simple terms, the lower the score, the better the model. The evaluation metric we will use to validate the model performance on the test data is the accuracy metric. The higher the accuracy score, the better the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model=Sequential()\n",
    "cnn_model.add(Conv2D(32,(5,5),input_shape=X_train.shape[1:],activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#cnn_model.add(Conv2D(16,(5,5),activation='relu'))\n",
    "#cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(128,activation='relu'))\n",
    "cnn_model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and Evaluating the model\n",
    "\n",
    "The first line of code below fits the model on the training data. We also provide the argument, epochs, which represents the number of training iterations. We have considered 5 epochs and the batch size of 150. The second line uses the model.evaluate() function to evaluate the model on the test data, while the third line prints the error and the accuracy score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.2511 - accuracy: 0.9262\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.0887 - accuracy: 0.9732\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 21s 51ms/step - loss: 0.0656 - accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.0515 - accuracy: 0.9846\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 22s 54ms/step - loss: 0.0429 - accuracy: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe5b00eddf0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(X_train,y_train,epochs=5,batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0380 - accuracy: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03798003867268562, 0.9872000217437744]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this guide, you have learned how to build a simple convolutional neural network using the high-performing deep learning library keras. You also learned about the different parameters that can be tuned depending on the problem statement and the data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
